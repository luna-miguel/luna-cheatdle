{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a60b847-aaba-4a22-83df-65644a34a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54045db7-fc03-4e14-9e8f-15a044e3f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"data/tweets.zip\")\n",
    "words = pd.read_csv(\"data/words_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85362efa-bb73-4497-b2e5-ed479211c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024305603723041"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(words[\"occurrence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36e1cff-2760-4f06-b467-20ccc0f8d7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_username</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>1482553374591660037</td>\n",
       "      <td>2022-01-16 03:20:43+00:00</td>\n",
       "      <td>bpszebes</td>\n",
       "      <td>Wordle 210 4/6\\n\\nâ¬›â¬›ğŸŸ¨ğŸŸ¨â¬›\\nğŸŸ©â¬›â¬›â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ¨â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>1482553387937898499</td>\n",
       "      <td>2022-01-16 03:20:46+00:00</td>\n",
       "      <td>cruisecoup</td>\n",
       "      <td>Wordle 210 4/6\\n\\nâ¬œâ¬œâ¬œâ¬œâ¬œ\\nğŸŸ©ğŸŸ©ğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©â¬œğŸŸ©ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>1482553422276698113</td>\n",
       "      <td>2022-01-16 03:20:55+00:00</td>\n",
       "      <td>DestroVega</td>\n",
       "      <td>Wordle 210 4/6\\n\\nâ¬œâ¬œâ¬œğŸŸ¨â¬œ\\nâ¬œğŸŸ©â¬œğŸŸ¨â¬œ\\nâ¬œğŸŸ©â¬œğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210</td>\n",
       "      <td>1482553436910628866</td>\n",
       "      <td>2022-01-16 03:20:58+00:00</td>\n",
       "      <td>brenmardash</td>\n",
       "      <td>Wordle 210 3/6\\n\\nâ¬œâ¬œğŸŸ¨â¬œâ¬œ\\nğŸŸ¨ğŸŸ¨â¬œâ¬œâ¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>1482553445726908420</td>\n",
       "      <td>2022-01-16 03:21:00+00:00</td>\n",
       "      <td>KatieHowse2</td>\n",
       "      <td>Wordle 210 3/6\\n\\nâ¬›â¬›ğŸŸ¨â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178449</th>\n",
       "      <td>519</td>\n",
       "      <td>1594492773662871553</td>\n",
       "      <td>2022-11-21 00:47:56+00:00</td>\n",
       "      <td>MaureenLamont</td>\n",
       "      <td>Wordle 519 2/6\\n\\nâ¬œğŸŸ©ğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178450</th>\n",
       "      <td>519</td>\n",
       "      <td>1594492932115124226</td>\n",
       "      <td>2022-11-21 00:48:33+00:00</td>\n",
       "      <td>Meeshbeer</td>\n",
       "      <td>Wordle 519 3/6\\n\\nâ¬œğŸŸ¨ğŸŸ©ğŸŸ¨â¬œ\\nâ¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178451</th>\n",
       "      <td>519</td>\n",
       "      <td>1594493005192658944</td>\n",
       "      <td>2022-11-21 00:48:51+00:00</td>\n",
       "      <td>BookChickie</td>\n",
       "      <td>Wordle 519 3/6\\n\\nâ¬›ğŸŸ©ğŸŸ©â¬›ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©â¬›ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178452</th>\n",
       "      <td>519</td>\n",
       "      <td>1594493051824754689</td>\n",
       "      <td>2022-11-21 00:49:02+00:00</td>\n",
       "      <td>aceynay</td>\n",
       "      <td>Wordle 519 3/6\\n\\nğŸŸ¨ğŸŸ©â¬œâ¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©â¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n\\nI pla...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178453</th>\n",
       "      <td>519</td>\n",
       "      <td>1594493111606030336</td>\n",
       "      <td>2022-11-21 00:49:16+00:00</td>\n",
       "      <td>thehollyzone</td>\n",
       "      <td>Wordle 519 2/6\\n\\nğŸŸ¨ğŸŸ¨â¬œâ¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n\\nâ¦@ScoreMyWor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1178454 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         day             tweet_id                 tweet_date tweet_username  \\\n",
       "0        210  1482553374591660037  2022-01-16 03:20:43+00:00       bpszebes   \n",
       "1        210  1482553387937898499  2022-01-16 03:20:46+00:00     cruisecoup   \n",
       "2        210  1482553422276698113  2022-01-16 03:20:55+00:00     DestroVega   \n",
       "3        210  1482553436910628866  2022-01-16 03:20:58+00:00    brenmardash   \n",
       "4        210  1482553445726908420  2022-01-16 03:21:00+00:00    KatieHowse2   \n",
       "...      ...                  ...                        ...            ...   \n",
       "1178449  519  1594492773662871553  2022-11-21 00:47:56+00:00  MaureenLamont   \n",
       "1178450  519  1594492932115124226  2022-11-21 00:48:33+00:00      Meeshbeer   \n",
       "1178451  519  1594493005192658944  2022-11-21 00:48:51+00:00    BookChickie   \n",
       "1178452  519  1594493051824754689  2022-11-21 00:49:02+00:00        aceynay   \n",
       "1178453  519  1594493111606030336  2022-11-21 00:49:16+00:00   thehollyzone   \n",
       "\n",
       "                                                tweet_text  score  \n",
       "0             Wordle 210 4/6\\n\\nâ¬›â¬›ğŸŸ¨ğŸŸ¨â¬›\\nğŸŸ©â¬›â¬›â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ¨â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      4  \n",
       "1             Wordle 210 4/6\\n\\nâ¬œâ¬œâ¬œâ¬œâ¬œ\\nğŸŸ©ğŸŸ©ğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©â¬œğŸŸ©ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      4  \n",
       "2             Wordle 210 4/6\\n\\nâ¬œâ¬œâ¬œğŸŸ¨â¬œ\\nâ¬œğŸŸ©â¬œğŸŸ¨â¬œ\\nâ¬œğŸŸ©â¬œğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      4  \n",
       "3                    Wordle 210 3/6\\n\\nâ¬œâ¬œğŸŸ¨â¬œâ¬œ\\nğŸŸ¨ğŸŸ¨â¬œâ¬œâ¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "4                    Wordle 210 3/6\\n\\nâ¬›â¬›ğŸŸ¨â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©â¬›â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "...                                                    ...    ...  \n",
       "1178449                     Wordle 519 2/6\\n\\nâ¬œğŸŸ©ğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      2  \n",
       "1178450              Wordle 519 3/6\\n\\nâ¬œğŸŸ¨ğŸŸ©ğŸŸ¨â¬œ\\nâ¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "1178451              Wordle 519 3/6\\n\\nâ¬›ğŸŸ©ğŸŸ©â¬›ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©â¬›ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "1178452  Wordle 519 3/6\\n\\nğŸŸ¨ğŸŸ©â¬œâ¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©â¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n\\nI pla...      3  \n",
       "1178453  Wordle 519 2/6\\n\\nğŸŸ¨ğŸŸ¨â¬œâ¬œğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n\\nâ¦@ScoreMyWor...      2  \n",
       "\n",
       "[1178454 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"score\"] = tweets[\"tweet_text\"].str[11]\n",
    "tweets[\"score\"] = pd.to_numeric(tweets['score'], errors='coerce')\n",
    "tweets.rename(columns={\"wordle_id\": \"day\"}, inplace=True)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f099ed-6a05-4c8c-85ef-f5b44c2cbffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day               0\n",
       "tweet_id          0\n",
       "tweet_date        0\n",
       "tweet_username    0\n",
       "tweet_text        0\n",
       "score             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcf5f3b-a0f2-4c97-bf1e-0e7fc5022b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.dropna(inplace=True)\n",
    "words[\"day\"] = pd.to_numeric(words['day'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "868f78af-f004-4545-bb5c-a38925d0ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word          0\n",
       "occurrence    0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0cf8ce9-179a-45b4-b645-5367e020e78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurrence</th>\n",
       "      <th>day</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_username</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admit</td>\n",
       "      <td>1.820914e-05</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2022-10-17 16:05:17+00:00</td>\n",
       "      <td>nickdeephoto</td>\n",
       "      <td>Wordle 485 2/6\\n\\nğŸŸ©ğŸŸ©â¬›ğŸŸ¨ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admit</td>\n",
       "      <td>1.820914e-05</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2022-10-17 16:05:18+00:00</td>\n",
       "      <td>Green_Mt_Girl</td>\n",
       "      <td>Wordle 485 4/6\\n\\nâ¬œâ¬œâ¬œğŸŸ©â¬œ\\nâ¬œğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ¨\\nğŸŸ¨â¬œâ¬œğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admit</td>\n",
       "      <td>1.820914e-05</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2022-10-17 16:05:20+00:00</td>\n",
       "      <td>Manab_Deka911</td>\n",
       "      <td>Wordle 485 2/6\\n\\nğŸŸ©â¬›â¬›ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admit</td>\n",
       "      <td>1.820914e-05</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2022-10-17 16:05:23+00:00</td>\n",
       "      <td>Aquagenerian</td>\n",
       "      <td>Wordle 485 3/6\\n\\nğŸŸ¨â¬›â¬›ğŸŸ¨ğŸŸ¨\\nğŸŸ©â¬›â¬›ğŸŸ¨â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admit</td>\n",
       "      <td>1.820914e-05</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2022-10-17 16:05:54+00:00</td>\n",
       "      <td>grcflwlkr</td>\n",
       "      <td>Wordle 485 4/6\\n\\nğŸŸ©â¬œğŸŸ©â¬œâ¬œ\\nâ¬œğŸŸ¨â¬œâ¬œğŸŸ¨\\nğŸŸ©â¬œğŸŸ¨ğŸŸ¨ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178449</th>\n",
       "      <td>zesty</td>\n",
       "      <td>7.402564e-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2022-05-05 02:43:24+00:00</td>\n",
       "      <td>KevinAWortman</td>\n",
       "      <td>Wordle 319 2/6\\n\\nğŸŸ¨â¬œğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178450</th>\n",
       "      <td>zesty</td>\n",
       "      <td>7.402564e-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2022-05-05 02:43:27+00:00</td>\n",
       "      <td>samsjag</td>\n",
       "      <td>Wordle 319 2/6\\n\\nğŸŸ©â¬›ğŸŸ©ğŸŸ¨â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178451</th>\n",
       "      <td>zesty</td>\n",
       "      <td>7.402564e-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2022-05-05 02:43:30+00:00</td>\n",
       "      <td>msghiorso</td>\n",
       "      <td>Wordle 319 3/6\\n\\nâ¬œğŸŸ¨ğŸŸ¨â¬œğŸŸ¨\\nğŸŸ¨â¬œâ¬œğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178452</th>\n",
       "      <td>zesty</td>\n",
       "      <td>7.402564e-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2022-05-05 02:43:32+00:00</td>\n",
       "      <td>katgarber</td>\n",
       "      <td>Wordle 319 5/6\\n\\nâ¬œğŸŸ¨â¬œğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ©ğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ©ğŸŸ©ğŸŸ©\\n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178453</th>\n",
       "      <td>zesty</td>\n",
       "      <td>7.402564e-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2022-05-05 02:43:34+00:00</td>\n",
       "      <td>RichardNobles</td>\n",
       "      <td>Wordle 319 4/6\\n\\nâ¬œâ¬œğŸŸ¨ğŸŸ¨â¬œ\\nâ¬œğŸŸ¨â¬œâ¬œğŸŸ¨\\nâ¬œğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1178454 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    occurrence    day                 tweet_date tweet_username  \\\n",
       "0        admit  1.820914e-05  485.0  2022-10-17 16:05:17+00:00   nickdeephoto   \n",
       "1        admit  1.820914e-05  485.0  2022-10-17 16:05:18+00:00  Green_Mt_Girl   \n",
       "2        admit  1.820914e-05  485.0  2022-10-17 16:05:20+00:00  Manab_Deka911   \n",
       "3        admit  1.820914e-05  485.0  2022-10-17 16:05:23+00:00   Aquagenerian   \n",
       "4        admit  1.820914e-05  485.0  2022-10-17 16:05:54+00:00      grcflwlkr   \n",
       "...        ...           ...    ...                        ...            ...   \n",
       "1178449  zesty  7.402564e-08  319.0  2022-05-05 02:43:24+00:00  KevinAWortman   \n",
       "1178450  zesty  7.402564e-08  319.0  2022-05-05 02:43:27+00:00        samsjag   \n",
       "1178451  zesty  7.402564e-08  319.0  2022-05-05 02:43:30+00:00      msghiorso   \n",
       "1178452  zesty  7.402564e-08  319.0  2022-05-05 02:43:32+00:00      katgarber   \n",
       "1178453  zesty  7.402564e-08  319.0  2022-05-05 02:43:34+00:00  RichardNobles   \n",
       "\n",
       "                                                tweet_text  score  \n",
       "0                           Wordle 485 2/6\\n\\nğŸŸ©ğŸŸ©â¬›ğŸŸ¨ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      2  \n",
       "1             Wordle 485 4/6\\n\\nâ¬œâ¬œâ¬œğŸŸ©â¬œ\\nâ¬œğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ¨\\nğŸŸ¨â¬œâ¬œğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      4  \n",
       "2                           Wordle 485 2/6\\n\\nğŸŸ©â¬›â¬›ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      2  \n",
       "3                    Wordle 485 3/6\\n\\nğŸŸ¨â¬›â¬›ğŸŸ¨ğŸŸ¨\\nğŸŸ©â¬›â¬›ğŸŸ¨â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "4        Wordle 485 4/6\\n\\nğŸŸ©â¬œğŸŸ©â¬œâ¬œ\\nâ¬œğŸŸ¨â¬œâ¬œğŸŸ¨\\nğŸŸ©â¬œğŸŸ¨ğŸŸ¨ğŸŸ¨\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©\\n...      4  \n",
       "...                                                    ...    ...  \n",
       "1178449                     Wordle 319 2/6\\n\\nğŸŸ¨â¬œğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      2  \n",
       "1178450                     Wordle 319 2/6\\n\\nğŸŸ©â¬›ğŸŸ©ğŸŸ¨â¬›\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      2  \n",
       "1178451              Wordle 319 3/6\\n\\nâ¬œğŸŸ¨ğŸŸ¨â¬œğŸŸ¨\\nğŸŸ¨â¬œâ¬œğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      3  \n",
       "1178452  Wordle 319 5/6\\n\\nâ¬œğŸŸ¨â¬œğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ¨ğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ©ğŸŸ¨â¬œ\\nğŸŸ©â¬œğŸŸ©ğŸŸ©ğŸŸ©\\n...      5  \n",
       "1178453       Wordle 319 4/6\\n\\nâ¬œâ¬œğŸŸ¨ğŸŸ¨â¬œ\\nâ¬œğŸŸ¨â¬œâ¬œğŸŸ¨\\nâ¬œğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ©\\nğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©      4  \n",
       "\n",
       "[1178454 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(words, tweets, on='day')\n",
    "df.drop(columns=['tweet_id'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ef3175-f067-4c77-ae2a-4169439d6a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.167,\n",
       " 1.492,\n",
       " 2.782,\n",
       " 4.253,\n",
       " 12.702,\n",
       " 2.288,\n",
       " 2.015,\n",
       " 6.094,\n",
       " 6.966,\n",
       " 0.153,\n",
       " 0.772,\n",
       " 4.025,\n",
       " 2.406,\n",
       " 6.749,\n",
       " 7.507,\n",
       " 1.929,\n",
       " 0.095,\n",
       " 5.987,\n",
       " 6.327,\n",
       " 9.056,\n",
       " 2.758,\n",
       " 0.978,\n",
       " 2.36,\n",
       " 0.15,\n",
       " 1.974,\n",
       " 0.074]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = pd.read_csv(\"data/letter-frequencies.csv\")\n",
    "freqs = freqs[[\"Letter\", \"English\"]]\n",
    "freqs = freqs[\"English\"].tolist()\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4678e62-edf8-4f3e-b565-d15129be5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the word in each row:\n",
    "\n",
    "    1. Put the word in lower case\n",
    "    2. Extract each letter in the word and make it it's own column\n",
    "    3. Convert to ASCII number using ord() function\n",
    "    4. subtract 97 to simplify char to number representation (a = 0, b = 1, c = 2, ...)\n",
    "    5. Get corresponding frequency using this number as index\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df[\"letter_1\"] = df[\"word\"].str.lower().str[0].apply(ord) - 97\n",
    "df[\"letter_2\"] = df[\"word\"].str.lower().str[1].apply(ord) - 97\n",
    "df[\"letter_3\"] = df[\"word\"].str.lower().str[2].apply(ord) - 97\n",
    "df[\"letter_4\"] = df[\"word\"].str.lower().str[3].apply(ord) - 97\n",
    "df[\"letter_5\"] = df[\"word\"].str.lower().str[4].apply(ord) - 97\n",
    "# df.drop(columns=[\"word\"], inplace=True)\n",
    "\n",
    "df[\"freq\"] = freqs[df[\"letter_1\"][0]] + freqs[df[\"letter_2\"][0]] + freqs[df[\"letter_3\"][0]] + freqs[df[\"letter_4\"][0]] +freqs[df[\"letter_5\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91ad5f6c-3403-41c2-a27c-b1533ecf4ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data overview:\n",
      "         occurrence           day         score      letter_1      letter_2  \\\n",
      "count  1.178454e+06  1.178454e+06  1.178454e+06  1.178454e+06  1.178454e+06   \n",
      "mean   3.371276e-05  3.475489e+02  4.126197e+00  1.085610e+01  1.073020e+01   \n",
      "std    1.325442e-04  9.180824e+01  1.077497e+00  7.345991e+00  6.420807e+00   \n",
      "min    1.427564e-08  2.100000e+02  2.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    4.708097e-07  2.600000e+02  3.000000e+00  4.000000e+00  7.000000e+00   \n",
      "50%    1.811237e-06  3.400000e+02  4.000000e+00  1.200000e+01  1.100000e+01   \n",
      "75%    8.992359e-06  4.260000e+02  5.000000e+00  1.800000e+01  1.500000e+01   \n",
      "max    1.333864e-03  5.190000e+02  6.000000e+00  2.500000e+01  2.400000e+01   \n",
      "\n",
      "           letter_3      letter_4      letter_5          freq  \n",
      "count  1.178454e+06  1.178454e+06  1.178454e+06  1.178454e+06  \n",
      "mean   1.099378e+01  1.081678e+01  1.209581e+01  3.084800e+01  \n",
      "std    7.009741e+00  6.749040e+00  7.508834e+00  3.907987e-14  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  3.084800e+01  \n",
      "25%    4.000000e+00  4.000000e+00  4.000000e+00  3.084800e+01  \n",
      "50%    1.300000e+01  1.100000e+01  1.100000e+01  3.084800e+01  \n",
      "75%    1.700000e+01  1.700000e+01  1.900000e+01  3.084800e+01  \n",
      "max    2.400000e+01  2.500000e+01  2.400000e+01  3.084800e+01   \n",
      "\n",
      "Null counts:\n",
      "word              0\n",
      "occurrence        0\n",
      "day               0\n",
      "tweet_date        0\n",
      "tweet_username    0\n",
      "tweet_text        0\n",
      "score             0\n",
      "letter_1          0\n",
      "letter_2          0\n",
      "letter_3          0\n",
      "letter_4          0\n",
      "letter_5          0\n",
      "freq              0\n",
      "dtype: int64 \n",
      "\n",
      "Duplicate row count: 10\n"
     ]
    }
   ],
   "source": [
    "def inspect_dataframe(input_df):\n",
    "    print(\"Data overview:\")\n",
    "    print(input_df.describe(), '\\n')\n",
    "\n",
    "    print(\"Null counts:\")\n",
    "    print(df.isnull().sum(), '\\n')\n",
    "\n",
    "    print(\"Duplicate row count:\", df.duplicated().sum())\n",
    "\n",
    "inspect_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa1f323f-f30b-4d44-88bc-1734e27f311d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m df[independent_variables]\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[dependent_variable]\n\u001b[0;32m----> 7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of our X_train data:\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mShape of our y_test data:\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2801\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2797\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2799\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2808\u001b[0m     )\n\u001b[1;32m   2809\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:1843\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m \n\u001b[1;32m   1815\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1843\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2268\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe test_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_test, n_classes)\n\u001b[1;32m   2263\u001b[0m     )\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;66;03m# Find the sorted list of instances for each class:\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m \u001b[38;5;66;03m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\n\u001b[0;32m-> 2268\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmergesort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mcumsum(class_counts)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   2269\u001b[0m )\n\u001b[1;32m   2271\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m   2274\u001b[0m     \u001b[38;5;66;03m# if there are ties in the class-counts, we want\u001b[39;00m\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# to make sure to break them anew in each iteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "independent_variables = ['letter_1', 'letter_2', 'letter_3', 'letter_4', 'letter_5', 'freq']\n",
    "dependent_variable = 'score'\n",
    "\n",
    "X = df[independent_variables]\n",
    "y = df[dependent_variable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "print('Shape of our X_train data:', X_train.shape, '\\nShape of our y_test data:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d4fbc-8b55-478c-bd86-e0f8a0ce6160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "oob_score = model.oob_score_\n",
    "print(f'Out-of-bag score: {oob_score}')\n",
    "\n",
    "# Model evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean absolute error: {mae}')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean squared error: {mse}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'Root mean squared error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f3302-eee8-4fa8-a024-1fc1f8f15726",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [5, 10, 15], \n",
    "    'max_leaf_nodes': [5, 10, 15],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c0387-c1f7-4964-8a68-4694daba4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv =  GridSearchCV(RandomForestRegressor(), param_grid=params, scoring=\"neg_mean_squared_error\")\n",
    "# grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd39654-1611-459f-a82c-6d0b1bfa9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'wordle_prediction.pkl'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36a41066-5e49-4824-b2c8-a7ae3391aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 'treat':\n",
      "**ğŸŒ³ Predicted average score via random forests:** \t4.17\n",
      "**ğ• No data found for this word in tweet data.**\n"
     ]
    }
   ],
   "source": [
    "def predict_score(word):\n",
    "\n",
    "    if (not word.isalpha() or len(word) != 5):\n",
    "        raise Exception(\n",
    "            \"Invalid word format. Please enter a five letter word using only alphabetic characters.\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"word\"] = [word]\n",
    "    df[\"letter_1\"] = df[\"word\"].str.lower().str[0].apply(ord) - 97\n",
    "    df[\"letter_2\"] = df[\"word\"].str.lower().str[1].apply(ord) - 97\n",
    "    df[\"letter_3\"] = df[\"word\"].str.lower().str[2].apply(ord) - 97\n",
    "    df[\"letter_4\"] = df[\"word\"].str.lower().str[3].apply(ord) - 97\n",
    "    df[\"letter_5\"] = df[\"word\"].str.lower().str[4].apply(ord) - 97\n",
    "\n",
    "    df[\"freq\"] =    freqs[df[\"letter_1\"][0]] + \\\n",
    "                    freqs[df[\"letter_2\"][0]] + \\\n",
    "                    freqs[df[\"letter_3\"][0]] + \\\n",
    "                    freqs[df[\"letter_4\"][0]] + \\\n",
    "                    freqs[df[\"letter_5\"][0]]\n",
    "\n",
    "    df.drop(columns=[\"word\"], inplace=True)\n",
    "    return model.predict(df)\n",
    "\n",
    "averages = df.groupby(\"word\", as_index=False)['score'].mean()\n",
    "word = \"treat\"\n",
    "\n",
    "prediction = predict_score(word)\n",
    "\n",
    "# If word isn't found in tweet data, None is returned for the average score\n",
    "average = None\n",
    "if word in averages[\"word\"].values:\n",
    "    average = averages[averages[\"word\"] == word][\"score\"].item()\n",
    "\n",
    "st.subheader(f\"Results for '{word}':\")\n",
    "st.markdown(\"**ğŸŒ³ Predicted average score via random forests:** \\t{:0.2f}\".format(prediction[0]))\n",
    "\n",
    "# Print average score according to tweet data if the word exists in it\n",
    "st.markdown((\"**ğ• No data found for this word in tweet data.**\" if average == None \\\n",
    "else \"**ğ• Average score via tweet data:** \\t\\t\\t{:0.2f}\".format(average)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4e020c4-e8e7-4dc2-8941-0da5f2114c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        countries = {\n",
    "            \"Idaho\":4.02,\n",
    "            \"Washington\":3.88,\n",
    "            \"Oregon\":3.94,\n",
    "            \"Colorado\":3.91,\n",
    "            \"Nevada\":4.13,\n",
    "            \"Utah\":3.91,\n",
    "            \"California\":3.90,\n",
    "            \"Alaska\":4.22,\n",
    "            \"Arizona\":3.95,\n",
    "            \"Hawaii\":4.12,\n",
    "            \"Kansas\":3.93,\n",
    "            \"Oklahoma\":3.92,\n",
    "            \"Texas\":3.92,\n",
    "            \"New Mexico\":4.05,\n",
    "            \"Missouri\":3.92,\n",
    "            \"Arkansas\":3.86,\n",
    "            \"Louisiana\":3.93,\n",
    "            \"Mississippi\":4.06,\n",
    "            \"Alabama\":3.81,\n",
    "            \"Tennessee\":3.89,\n",
    "            \"Georgia\":3.92,\n",
    "            \"South Carolina\":4.02,\n",
    "            \"Kentucky\":3.93,\n",
    "            \"Florida\":3.97,\n",
    "            \"North Carolina\":4.01,\n",
    "            \"Virginia\":3.95,\n",
    "            \"Maryland\":3.86,\n",
    "            \"Delaware\":3.70,\n",
    "            \"New Jersey\":3.97,\n",
    "            \"New York\":3.84,\n",
    "            \"Massachusetts\":3.91,\n",
    "            \"Rhode Island\":3.99,\n",
    "            \"New Hampshire\": 3.73,\n",
    "            \"Maine\":4.04,\n",
    "            \"Vermont\":3.83,\n",
    "            \"Indiana\":3.91,\n",
    "            \"Pennsylvania\":3.91,\n",
    "            \"Connecticut\":3.87,\n",
    "            \"West Virginia\":3.97,\n",
    "            \"Ohio\":3.94,\n",
    "            \"Michigan\":3.97,\n",
    "            \"Wisconsin\":4.08,\n",
    "            \"Minnesota\":3.83,\n",
    "            \"North Dakota\":3.65,\n",
    "            \"Illinois\":3.88,\n",
    "            \"Iowa\":3.89,\n",
    "            \"Nebraska\":4.22,\n",
    "            \"South Dakota\":3.79,\n",
    "            \"Wyoming\":4.00,\n",
    "            \"Montana\":4.08\n",
    "        }\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d3e36f9-d2c3-46c8-97d1-376c70fbb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(countries, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4957403-e246-47f8-8c42-cf50a2e2ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919e53b-9f52-4427-be96-4a9809d95842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
